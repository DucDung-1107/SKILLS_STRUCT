#!/usr/bin/env python3
"""
ü§ñ AI Integration Utilities
C√°c h√†m ti·ªán √≠ch cho t√≠ch h·ª£p AI/ML v√† NLP
"""

import json
import re
import requests
from typing import Dict, List, Any, Optional, Tuple
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

# AI API Configuration
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta"
DEFAULT_MODEL = "gemini-1.5-flash"

def call_gemini_api(prompt: str, api_key: str, model: str = DEFAULT_MODEL, 
                   **kwargs) -> Optional[Dict[str, Any]]:
    """
    G·ªçi Gemini API
    """
    if not api_key:
        logger.error("API key is required")
        return None
    
    url = f"{GEMINI_API_BASE}/models/{model}:generateContent"
    
    # Default generation config
    generation_config = {
        "temperature": kwargs.get("temperature", 0.1),
        "top_p": kwargs.get("top_p", 0.95),
        "top_k": kwargs.get("top_k", 40),
        "max_output_tokens": kwargs.get("max_output_tokens", 8192),
        "response_mime_type": kwargs.get("response_mime_type", "application/json")
    }
    
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ],
        "generationConfig": generation_config
    }
    
    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": api_key
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        
        # Extract text from response
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                parts = candidate["content"]["parts"]
                if len(parts) > 0 and "text" in parts[0]:
                    return {
                        "success": True,
                        "text": parts[0]["text"],
                        "full_response": result
                    }
        
        return {
            "success": False,
            "error": "Invalid response format",
            "full_response": result
        }
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error calling Gemini API: {e}")
        return {
            "success": False,
            "error": str(e)
        }
    except Exception as e:
        logger.error(f"Unexpected error in Gemini API call: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def extract_features_with_ai(text_content: str, api_key: str) -> Optional[Dict[str, Any]]:
    """
    Tr√≠ch xu·∫•t features t·ª´ CV b·∫±ng AI
    """
    prompt = f"""
    Extract the following information from this resume text and return it as a JSON object. 
    If any information is not found, use null or empty array.

    Required fields:
    - name: Full name of the candidate
    - email: Email address
    - phone: Phone number
    - address: Full address or location
    - linkedin: LinkedIn profile URL
    - skills: List of technical skills (as array)
    - experience_years: Total years of experience (as number)
    - education: Highest education degree
    - university: Name of university/college
    - certifications: List of certifications (as array)
    - languages: List of languages spoken (as array)
    - job_titles: List of job titles from experience (as array)
    - companies: List of companies worked at (as array)
    - summary: Brief professional summary (2-3 sentences)

    Resume text:
    {text_content}

    Return only valid JSON format without any additional text:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            # Parse JSON response
            features = json.loads(result["text"])
            return features
        except json.JSONDecodeError:
            # Try to extract JSON from response
            json_match = re.search(r'\{.*\}', result["text"], re.DOTALL)
            if json_match:
                try:
                    features = json.loads(json_match.group())
                    return features
                except json.JSONDecodeError:
                    logger.error("Could not parse JSON from AI response")
                    return None
    
    return None

def generate_skill_taxonomy_with_ai(employee_data: List[Dict[str, Any]], 
                                  api_key: str) -> Optional[Dict[str, Any]]:
    """
    T·∫°o skill taxonomy t·ª´ d·ªØ li·ªáu nh√¢n vi√™n b·∫±ng AI
    """
    # Convert data to JSON string
    data_json = json.dumps(employee_data, ensure_ascii=False, indent=2)
    
    prompt = f"""
    H√£y ph√¢n t√≠ch d·ªØ li·ªáu nh√¢n vi√™n sau v√† t·∫°o m·ªôt skill taxonomy graph d·∫°ng c√¢y ph√¢n c·∫•p t·ª´ t·ªïng qu√°t ƒë·∫øn chi ti·∫øt.

    D·ªØ li·ªáu ƒë·∫ßu v√†o:
    {data_json}

    Y√™u c·∫ßu:
    1. T·∫°o c·∫•u tr√∫c c√¢y skill taxonomy t·ª´ department/team ‚Üí skill group ‚Üí skill ‚Üí sub-skill
    2. M·ªói node c√≥ th√¥ng tin: id, name, type, level, employees, proficiency_stats
    3. M·ªói edge th·ªÉ hi·ªán quan h·ªá parent-child
    4. Bao g·ªìm th√¥ng tin m√†u s·∫Øc v√† ƒë·ªô ƒë·∫≠m d·ª±a tr√™n proficiency level
    5. K·∫øt qu·∫£ c√≥ th·ªÉ import v√†o Mermaid, D3.js ho·∫∑c graph editor

    Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c:
    {{
        "metadata": {{
            "title": "Employee Skill Taxonomy",
            "description": "Hierarchical skill structure", 
            "created_date": "{datetime.now().isoformat()}",
            "total_employees": <number>,
            "total_skills": <number>
        }},
        "nodes": [
            {{
                "id": "unique_id",
                "name": "Node Name", 
                "type": "root|skill_group|skill|sub_skill",
                "level": <number>,
                "color": "#hexcolor",
                "employees": ["emp1", "emp2"],
                "employee_count": <number>,
                "proficiency_stats": {{
                    "beginner": <count>,
                    "intermediate": <count>, 
                    "advanced": <count>,
                    "expert": <count>
                }}
            }}
        ],
        "edges": [
            {{
                "id": "edge_id",
                "source": "parent_node_id",
                "target": "child_node_id", 
                "type": "contains|includes|specializes",
                "weight": 1.0
            }}
        ],
        "color_scheme": {{
            "root": "#808080",
            "skill_group": "#ff7f0e",
            "skill": "#2ca02c", 
            "sub_skill": "#d62728"
        }}
    }}

    Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng c√≥ text th√™m:
    """
    
    result = call_gemini_api(prompt, api_key, max_output_tokens=8192)
    
    if result and result.get("success"):
        try:
            taxonomy = json.loads(result["text"])
            return taxonomy
        except json.JSONDecodeError:
            # Try to extract JSON
            json_match = re.search(r'\{.*\}', result["text"], re.DOTALL)
            if json_match:
                try:
                    taxonomy = json.loads(json_match.group())
                    return taxonomy
                except json.JSONDecodeError:
                    logger.error("Could not parse taxonomy JSON from AI response")
    
    return None

def generate_recommendations(taxonomy: Dict[str, Any], api_key: str, 
                           max_recommendations: int = 8) -> List[Dict[str, Any]]:
    """
    T·∫°o skill recommendations b·∫±ng AI
    """
    # Prepare current taxonomy summary
    nodes_summary = []
    for node in taxonomy.get("nodes", []):
        nodes_summary.append({
            "name": node.get("name"),
            "type": node.get("type"),
            "employee_count": node.get("employee_count", 0)
        })
    
    prompt = f"""
    D·ª±a tr√™n skill taxonomy hi·ªán t·∫°i, h√£y ƒë·ªÅ xu·∫•t {max_recommendations} skills m·ªõi ƒë·ªÉ m·ªü r·ªông taxonomy.

    Taxonomy hi·ªán t·∫°i:
    {json.dumps(nodes_summary, ensure_ascii=False, indent=2)}

    Y√™u c·∫ßu ƒë·ªÅ xu·∫•t:
    1. Skills ph√π h·ª£p v·ªõi xu h∆∞·ªõng c√¥ng ngh·ªá hi·ªán t·∫°i
    2. Skills b·ªï sung cho c√°c skill groups ƒë√£ c√≥
    3. Skills quan tr·ªçng cho s·ª± ph√°t tri·ªÉn ngh·ªÅ nghi·ªáp
    4. ∆Øu ti√™n skills c√≥ nhu c·∫ßu cao tr√™n th·ªã tr∆∞·ªùng

    Tr·∫£ v·ªÅ JSON array v·ªõi format:
    [
        {{
            "name": "Skill Name",
            "type": "skill_group|skill|sub_skill",
            "parent_name": "Parent Skill Name (if applicable)",
            "description": "Brief description of the skill",
            "category": "technology|soft_skill|management|security|design|business",
            "level": 1-5,
            "priority": "high|medium|low"
        }}
    ]

    Ch·ªâ tr·∫£ v·ªÅ JSON array h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            recommendations = json.loads(result["text"])
            if isinstance(recommendations, list):
                return recommendations[:max_recommendations]
        except json.JSONDecodeError:
            logger.error("Could not parse recommendations JSON")
    
    return []

def analyze_skill_gaps(required_skills: List[str], available_skills: List[str], 
                      api_key: str) -> Dict[str, Any]:
    """
    Ph√¢n t√≠ch skill gaps b·∫±ng AI
    """
    prompt = f"""
    Ph√¢n t√≠ch kho·∫£ng c√°ch k·ªπ nƒÉng d·ª±a tr√™n y√™u c·∫ßu v√† k·ªπ nƒÉng hi·ªán c√≥:

    K·ªπ nƒÉng y√™u c·∫ßu:
    {json.dumps(required_skills, ensure_ascii=False)}

    K·ªπ nƒÉng hi·ªán c√≥:
    {json.dumps(available_skills, ensure_ascii=False)}

    H√£y ph√¢n t√≠ch v√† ƒë∆∞a ra:
    1. K·ªπ nƒÉng c√≤n thi·∫øu (gaps)
    2. K·ªπ nƒÉng th·ª´a 
    3. M·ª©c ƒë·ªô matching
    4. ƒê·ªÅ xu·∫•t training/hiring
    5. ƒê·ªô ∆∞u ti√™n cho t·ª´ng skill gap

    Tr·∫£ v·ªÅ JSON:
    {{
        "missing_skills": ["skill1", "skill2"],
        "extra_skills": ["skill3", "skill4"],  
        "matching_skills": ["skill5", "skill6"],
        "coverage_percent": <percentage>,
        "gap_analysis": [
            {{
                "skill": "Missing Skill Name",
                "priority": "high|medium|low",
                "reason": "Why this skill is important",
                "recommendation": "Specific action to address gap"
            }}
        ],
        "training_recommendations": ["recommendation1", "recommendation2"],
        "hiring_recommendations": ["recommendation1", "recommendation2"]
    }}

    Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            analysis = json.loads(result["text"])
            return analysis
        except json.JSONDecodeError:
            logger.error("Could not parse gap analysis JSON")
    
    return {}

def cluster_skills(skills: List[str], api_key: str) -> List[List[str]]:
    """
    Cluster skills theo semantic similarity b·∫±ng AI
    """
    prompt = f"""
    H√£y ph√¢n nh√≥m c√°c skills sau ƒë√¢y theo semantic similarity v√† domain:

    Skills:
    {json.dumps(skills, ensure_ascii=False)}

    Y√™u c·∫ßu:
    1. Nh√≥m c√°c skills c√≥ li√™n quan v·ªõi nhau
    2. M·ªói nh√≥m n√™n c√≥ 2-8 skills
    3. ƒê·∫∑t t√™n cho m·ªói nh√≥m
    4. S·∫Øp x·∫øp t·ª´ nh√≥m quan tr·ªçng nh·∫•t

    Tr·∫£ v·ªÅ JSON:
    {{
        "clusters": [
            {{
                "name": "Cluster Name",
                "skills": ["skill1", "skill2", "skill3"],
                "description": "Brief description of this cluster"
            }}
        ]
    }}

    Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            clusters_data = json.loads(result["text"])
            clusters = []
            for cluster in clusters_data.get("clusters", []):
                cluster_skills = cluster.get("skills", [])
                if cluster_skills:
                    clusters.append(cluster_skills)
            return clusters
        except json.JSONDecodeError:
            logger.error("Could not parse clusters JSON")
    
    return []

def generate_mermaid_code(taxonomy: Dict[str, Any], api_key: str) -> str:
    """
    T·∫°o Mermaid diagram code t·ª´ taxonomy b·∫±ng AI
    """
    prompt = f"""
    T·∫°o Mermaid diagram code t·ª´ skill taxonomy n√†y:

    {json.dumps(taxonomy, ensure_ascii=False, indent=2)}

    Y√™u c·∫ßu:
    1. S·ª≠ d·ª•ng graph TD (top-down)
    2. T·∫°o c√°c node v·ªõi shape ph√π h·ª£p v·ªõi type
    3. Th√™m m√†u s·∫Øc cho c√°c node
    4. T·∫°o connections gi·ªØa parent-child
    5. Code ph·∫£i ch·∫°y ƒë∆∞·ª£c tr√™n Mermaid

    Ch·ªâ tr·∫£ v·ªÅ Mermaid code thu·∫ßn t√∫y, kh√¥ng c√≥ markdown wrapper:
    """
    
    result = call_gemini_api(prompt, api_key, response_mime_type="text/plain")
    
    if result and result.get("success"):
        return result["text"].strip()
    
    return ""

def extract_job_requirements(job_description: str, api_key: str) -> Dict[str, Any]:
    """
    Tr√≠ch xu·∫•t requirements t·ª´ job description b·∫±ng AI
    """
    prompt = f"""
    Tr√≠ch xu·∫•t th√¥ng tin y√™u c·∫ßu t·ª´ job description n√†y:

    {job_description}

    Tr·∫£ v·ªÅ JSON:
    {{
        "position": "Job title",
        "required_skills": ["skill1", "skill2"],
        "preferred_skills": ["skill3", "skill4"],
        "experience_years": <number>,
        "education_level": "bachelor|master|phd|diploma",
        "certifications": ["cert1", "cert2"],
        "soft_skills": ["skill1", "skill2"],
        "responsibilities": ["task1", "task2"],
        "company_info": "Brief company description",
        "salary_range": "If mentioned",
        "location": "Work location"
    }}

    Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            requirements = json.loads(result["text"])
            return requirements
        except json.JSONDecodeError:
            logger.error("Could not parse job requirements JSON")
    
    return {}

def match_candidate_to_job(candidate_skills: List[str], job_requirements: Dict[str, Any], 
                          api_key: str) -> Dict[str, Any]:
    """
    Matching candidate v·ªõi job requirements b·∫±ng AI
    """
    prompt = f"""
    ƒê√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa candidate v·ªõi job requirements:

    Candidate skills:
    {json.dumps(candidate_skills, ensure_ascii=False)}

    Job requirements:
    {json.dumps(job_requirements, ensure_ascii=False)}

    Tr·∫£ v·ªÅ JSON:
    {{
        "match_score": <0-100>,
        "matching_skills": ["skill1", "skill2"],
        "missing_skills": ["skill3", "skill4"],
        "extra_skills": ["skill5", "skill6"],
        "skill_gaps": [
            {{
                "skill": "Missing skill",
                "importance": "high|medium|low",
                "can_be_trained": true/false
            }}
        ],
        "recommendations": [
            "Specific recommendation for improvement"
        ],
        "interview_questions": [
            "Suggested interview question"
        ],
        "decision": "hire|interview|reject",
        "reasoning": "Brief explanation of the decision"
    }}

    Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            match_result = json.loads(result["text"])
            return match_result
        except json.JSONDecodeError:
            logger.error("Could not parse matching result JSON")
    
    return {}

def generate_learning_path(current_skills: List[str], target_role: str, 
                         api_key: str) -> List[Dict[str, Any]]:
    """
    T·∫°o learning path b·∫±ng AI
    """
    prompt = f"""
    T·∫°o learning path t·ª´ skills hi·ªán t·∫°i ƒë·∫øn target role:

    Current skills: {json.dumps(current_skills, ensure_ascii=False)}
    Target role: {target_role}

    Tr·∫£ v·ªÅ JSON array v·ªõi learning steps theo th·ª© t·ª±:
    [
        {{
            "step": 1,
            "skill": "Skill to learn",
            "type": "technical|soft_skill|certification",
            "difficulty": "beginner|intermediate|advanced",
            "estimated_weeks": <number>,
            "prerequisites": ["prerequisite1", "prerequisite2"],
            "resources": [
                {{
                    "type": "course|book|practice|project",
                    "name": "Resource name",
                    "url": "URL if available",
                    "cost": "free|paid"
                }}
            ],
            "milestone": "What you should achieve",
            "assessment": "How to verify you learned it"
        }}
    ]

    Ch·ªâ tr·∫£ v·ªÅ JSON array h·ª£p l·ªá:
    """
    
    result = call_gemini_api(prompt, api_key)
    
    if result and result.get("success"):
        try:
            learning_path = json.loads(result["text"])
            if isinstance(learning_path, list):
                return learning_path
        except json.JSONDecodeError:
            logger.error("Could not parse learning path JSON")
    
    return []

def validate_ai_response(response_text: str, expected_format: str = "json") -> bool:
    """
    Validate AI response format
    """
    if not response_text:
        return False
    
    if expected_format == "json":
        try:
            json.loads(response_text)
            return True
        except json.JSONDecodeError:
            return False
    
    return True

def clean_ai_response(response_text: str) -> str:
    """
    Clean AI response (remove markdown, extra formatting)
    """
    if not response_text:
        return ""
    
    # Remove markdown code blocks
    response_text = re.sub(r'```json\s*|\s*```', '', response_text)
    response_text = re.sub(r'```\s*|\s*```', '', response_text)
    
    # Remove extra whitespace
    response_text = response_text.strip()
    
    return response_text
